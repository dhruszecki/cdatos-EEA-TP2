---
title: "eea2020_tp2_dario_hruszecki"
author: "Darío Hruszecki"
output: html_document
---

```{r}
# Carga de librerías
library(tidyverse)
library(tidymodels)
library(GGally)
library(corrr)
library(knitr)
library(ggrepel)
library(kableExtra)
library(here)
```

# EEA 2020 - TP2 - Darío Hruszecki

## DATOS

El dataset de precios de inmuebles proviene  de [Properati](https://www.properati.com.ar/data/). El mismo ya fue filtrado por los docentes y a su vez se encuentra particionado en subconjuntos de training y test.

### Carga partición de entrenamiento
```{r}
train_ds <- read_csv(here("/ds/ar_properties_train.csv"))
```

### Describimos el dataset

#### Previsualizamos los datos
```{r}
head(train_ds)
```
#### Vemos las dimensiones del DS y como se distribuyen los valores de las variables
```{r}
dim_desc(train_ds)
```

#### Vemos como se distribuyen los valores de las variables
```{r}
summary(train_ds)
```
#### Valores únicos para la variable alfanumérica *l3*
```{r}
unique(train_ds$l3)
```
#### Valores únicos para la variable alfanumérica *property_type*
```{r}
unique(train_ds$property_type)
```
#### Verificamos si hay valores NA en las variables
```{r}
apply(train_ds, 2, function(x) any(is.na(x)))
```

```{r}
table(train_ds$property_type)
```
```{r}
tail(table(train_ds$l3)[], 10)
```


#### Observaciones sobre los datos

* El dataset contiene 8 variables y 32132 registros
* De las 8 variables, 5 son núnericas y 3 son alfanuméricas
* De las variables alfanuméricas tenemos el barrio (*l3*) y el tipo de propiedad (*property_type*). La tercera es un UUID para la propiedad (*id*)
* En base a los valores únicos encontrados para *l3* podemos inferir que las propiedades pertenecen a CABA en su totalidad.
* De las númericas, además del precio (*price*) tenemos variables que describen la propiedad: cantidad de habitaciones (*rooms*), cantidad de baños (*bathrooms*), supervicie total (*surface_total*) y superficie cubierta (*surface_covered*)
* No se observan valores NA en ninguna de las columnas



## CONSIGNA


## Modelo de Regresion Lineal Multiple


### Generación del Modelo con todas las covariables

Vamos a generar un modelo que utilice todas las covariables presentes en nuestro **dataset de training** para buscar predecir el **precio**.
```{r}
modelo_todas_covariables <- lm(
  price ~ rooms + bathrooms + surface_total + surface_covered + property_type + l3, 
  data = train_ds
  )
tidy_mtc <- tidy(modelo_todas_covariables, conf.int = TRUE)
tidy_mtc
```

### Análisis del Modelo con todas las covariables

#### Significado de los coeficientes estimados

- El valor de la ordenada al origen (-109.143,78) es el valor del precio esperado para una propiedad sin ambientes o superficie y que no pertenece a ningún tipo (Casa, PH o Departamento) y que no se encuentra en ninguna zona (es una inferencia más teórica de nuestro modelo dado que no es representativo en la realidad).

- El coeficiente estimado de ambientes es -4359,73. Esto implica que manteniendo constantes todas nuestras otras covariables, un aumento de un ambiente a nuestra propiedad corresponde a una quita de $4359, *en promedio* en el precio de una propiedad.

- El coeficiente estimado de baños es 34.367,21. Esto implica que manteniendo constantes todas nuestras otras covariables, un aumento de un baño a nuestra propiedad corresponde a una aumento de $34.367, *en promedio* en el precio de una propiedad.

- El coeficiente estimado de superficie total es 890,56. Esto implica que manteniendo constantes todas nuestras otras covariables, un aumento en una unidad de superficie (m2) a nuestra propiedad corresponde a una aumento de $890, *en promedio* en el precio de una propiedad.

- El coeficiente estimado de superficie cubierta es 1.497,93. Esto implica que manteniendo constantes todas nuestras otras covariables, un aumento en una unidad de superficie cubierta (m2) a nuestra propiedad corresponde a una aumento de $1.498, *en promedio* en el precio de una propiedad.

- Los coeficientes de tipo de propiedad (Departamento y PH) indican cuanto aumenta la función de respuesta (precio) para un departamento o un ph en comparación a una casa (categoría basal). Sus valores de β respectivos son para los departamentos 91.485,94 y para los PHs 46.220,04

- Finalmente tenemos 56 coeficientes para la variable **l3** que representan en cuanto aumenta o se reduce el precio de una propiedad dependiendo de la zona específica a la cual pertenece.


#### Significatividad de variables dummies

Observamos en nuestro modelo dos tipos distintos de variables *dummies*. Aquellas que responden a la variable **property_type** y aquellas que responden a la variable **l3**.

Podemos observar que los p-valores asociados a los coeficientes de la variable **property_type**, resultan estadísticamente significativos.
En cuanto a aquellos p-valores asociados a los coeficientes de la variable **l3** nos encontramos con que en algunos casos resultan estadísticamente significativos (*l3Balvanera* con un p-valor de 0,000002) pero en otros casos no lo es (*l3Agronomía* con un p-valor de 0,9).

Además podemos observar que los intervalos de confianza para las variables dummy que responden a **property_type** no contienen al 0 y en lineas generales, aquellos que responden a la variable **l3** si lo contienen.

Vamos a aplicar un Test F (test de ignificatividad global) para medir la significatividad conjunta de las variables categóricas en nuestro modelo.
```{r}
tidy(
  anova(modelo_todas_covariables)
)
```
 La tabla de ANOVA muestra que tanto la variable categorica **property_type** como **l3** en su conjunto resultan estadísticamente significativas (p-valor < 0.05). Por ende buscaremos determinar cuales de las comparaciones entre grupos son estadísticamente significativas.
 
#### Evaluación del Modelo

Graficamos los coeficientes estimados.
```{r warning=FALSE, fig.width=11, fig.height=11}
ggplot(
  tidy_mtc, 
  aes(
    estimate, 
    term, 
    xmin = conf.low, 
    xmax = conf.high, 
    height = 0
  )
) +
  geom_point(
    color = "forestgreen", 
    size=2
  ) +
  geom_vline(
    xintercept = 0, 
    lty = 4, 
    color = "black"
  ) +
  geom_errorbarh(
    color = "forestgreen", 
    size=1
  ) + 
  theme_bw() +
  labs(
    y = "Coeficientes β", 
    x = "Estimación"
  )
```
De analizar el grafico de los coeficientes podemos visualizar los intervalos de confianza de las distintas variables. Claramente podemos observar como hay muchas variables dummy asociadas a la variable **l3** que incluyen el 0 dentro de sus intervalos de confianza y por ende podemos asumir que estas variables no son significativas para explicar el precio de las propiedades.

Y ahora analizamos las medidas del resumen global del modelo. 
```{r}
glance(modelo_todas_covariables)
```
 Analizando el valor del $Rˆ2$ ajustado del modelo, podemos ver que el mismo parece explicar un buen porcentaje de variabilidad del conjunto. 
 
 ### Generación de Modelo sin **l3**
 
 Ahora vamos a generar un modelo sin la variable **l3** para comparar y analizar el impacto de esta variable en nuestro modelo previo.
```{r}
modelo_sin_l3 <- lm(
  price ~ rooms + bathrooms + surface_total + surface_covered + property_type, 
  data = train_ds
)
tidy_msl3 <- tidy(modelo_sin_l3, conf.int = TRUE)
tidy_msl3
```
Podemos observar como en nuestro nuevo modelo, los p-valores de todos los coeficientes asociados a nuestras variables resultan estadísticamente significativos (p-valor < 0.05). Además ninguno de los intervalos de confianza de nuestros coeficientes incluyen el 0.

Vamos a aplicar un Test F (test de ignificatividad global) para medir la significatividad conjunta de las variables categóricas en nuestro modelo. 
```{r}
tidy(
  anova(modelo_sin_l3)
)
``` 
Los resultados del ANOVA muestran que todas las variables utilizadas son estadisticamente significativas (respaldando lo visto en el anterior modelo).

Y ahora analizamos comparativamente las medidas del resumen global de nuestros 2 modelos. 
```{r}
modelos = list(
  modelo_todas_covariables = modelo_todas_covariables,
  modelo_sin_l3 = modelo_sin_l3
)

purrr::map_df(modelos, broom::glance, .id = "model")
```
Como se puede observar, el **modelo_todas_covariables** es el modelo que mejor explica la variabilidad en nuestro conjunto (evaluamos el coeficiente $Rˆ2$ ajustado para ambos).

## Creación de Variables

### Armado de nuevo dataset

En nuestro analisis previo, observamos como algunos barrios (variable **l3**) eran significativos y otros no. Por ende, vamos a proponer la generación de una nueva variable **barrios** que nos permite agrupar mas eficientemente nuestros datos.

Para hacerla, vamos a generar otra variable **precio_m2** que contiene el valor de **price** sobre el total de metros cuadrados de superficie (**surface_total**). Luego, sobre esta variable, agruparemos los datos en tres categorías (variable **barrios**):
- precio_bajo: aquellas propiedades con valores iguales o inferiores al Q1 de nuestra variable **precio_m2**
- precio_medio: aquellas propiedades con valores superiores al Q1 y con valores inferiores o iguales al Q3 de nuestra variable **precio_m2**
- precio_alto: aquellas propiedades con valores superiores al Q3 de nuestra variable **precio_m2**

```{r}
train_ds = train_ds %>%
  mutate(
    precio_m2 = price / surface_total,
    barrios = factor(
      case_when(
        precio_m2 <= quantile(precio_m2)[2] ~ "precio_bajo",
        precio_m2 > quantile(precio_m2)[2] & precio_m2 <= quantile(precio_m2)[4] ~ "precio_medio",
        precio_m2 > quantile(precio_m2)[4] ~ "precio_alto"
      )
    )
  )

train_ds
```

### Generación de un nuevo modelo

Ahora vamos a generar un nuevo modelo incluyendo nuestras nueva covariables **barrios**.
```{r}
modelo_barrios <- lm(
  price ~ rooms + bathrooms + surface_total + surface_covered + property_type + barrios , 
  data = train_ds
) 
tidy_mb <- tidy(modelo_barrios, conf.int = TRUE)
tidy_mb
```
Podemos apreciar como los p-valores de los coeficientes resultan significativos. 
Sin embargo el valor de mi coeficiente $B_0$ parece no ser significativo (p-valor > 0.05). Más aún, podemos comprobar que su intervalo de confianza incluye el 0.

### Evaluación Modelo Barrios

Comparamos nuestros 3 modelos.
```{r}
modelos = list(
  modelo_todas_covariables = modelo_todas_covariables,
  modelo_sin_l3 = modelo_sin_l3,
  modelo_barrios = modelo_barrios
)

purrr::map_df(modelos, broom::glance, .id = "model") %>%
  arrange(adj.r.squared)
```
Podemos observar como el modelo que mejor explica la variabilidad, $Rˆ2$ ajustado, es nuestro *modelo_barrios* seguido en orden por *modelo_todas_covariables* y *modelo_sin_l3*.

Más aún, como el *modelo_barrios* tiene coeficientes que son estadísticamente significativos, resulta más útil para el análisis del precio de nuestras propiedades (a pesar que la información de los valores de **l3** podría ser más util en un análisis mas profundo).


### Generación Modelo Supercicie Descubierta

Dada la fuerte correlación entre las variables  **surface_total** y **surface_covered**, vamos a generar una nueva variable llamada **sup_descubierta** que representa la diferencia entre la superficie total y la cubierta.
```{r}
train_ds = train_ds %>%
  mutate(sup_descubierta = surface_total - surface_covered)

train_ds 
```

Ahora con nuestra nueva variable, vamos a generar un nuevo modelo que incluya la variable **sup_descubierta** en reemplazo de la variable **surface_total**.
```{r}
modelo_sup_descubierta <- lm(
  price ~ rooms + bathrooms + sup_descubierta + surface_covered + property_type + precio_m2 + barrios , 
  data = train_ds
) 
tidy_msd <- tidy(modelo_sup_descubierta, conf.int = TRUE)
tidy_msd
```
Podemos observar como los p-valores de todos nuestros coeficientes resultan significativos en nuestro nuevo modelo.

```{r}
tidy(
  anova(modelo_sup_descubierta)
)
```
Y al ejecutar el Test F, validamos el mismo.

Ahora comparamos todos los modelos que generamos.
```{r}
modelos = list(
  modelo_todas_covariables = modelo_todas_covariables,
  modelo_sin_l3 = modelo_sin_l3,
  modelo_barrios = modelo_barrios,
  modelo_sup_descubierta = modelo_sup_descubierta
)

purrr::map_df(modelos, broom::glance, .id = "model") %>%
  arrange(adj.r.squared)
```
Podemos observar como nuestro nuevo modelo *modelo_sup_descubierta* es el que mejor explica la variabilidad.

## Diagnóstico del Modelo

Vamos a evaluar nuestro modelo lineal con la variable **sup_descubierta**
```{r}
plot(modelo_sup_descubierta)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad parece que no se respeta. Vemos la existencía de heterocedasticidad a medida que aumentan las predicciones. Se resaltan 2 observaciones.
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho.
- *Residual vs leverage:*Existen cuatro puntos con un leverage bastante alto. Y se identifican 2 puntos como posibles outliers. .

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal. No parece ser concluyente respecto de la homocedasticidad, definitivamente existe una falta de normalidad y hay presencia de observaciones de alto leverage

## Modelo Log(*price*)

Vamos a generar un modelo para predecir el logaritmo natural de la variable **price**
$$
log(price) = \beta_0 + \beta_1log(rooms) + \beta_2log(bathrooms) + \beta_3log(surface\_covered) + \beta_4property\_type + \beta_5barrio + \beta_6surface\_patio
$$

Para esto vamos a generar nuestros nuevas variables
```{r}
modelo_log = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + barrios + sup_descubierta,
  data = train_ds
)
tidy_ml <- tidy(modelo_log, conf.int = TRUE)
tidy_ml
```

```{r}
tidy(
  anova(modelo_log)
)
```
De nuestro modelo confirmamos que todos los coeficientes resultan significativos.

Ahora comparamos nuestro nuevo *modelo_log* con nuestro *modelo_sup_descubierta*.
```{r}
modelos = list(
  modelo_log = modelo_log,
  modelo_sup_descubierta = modelo_sup_descubierta
)

purrr::map_df(modelos, broom::glance, .id = "model")
```
Observamos que el mismo explica mejor la variabilidad $Rˆ2$

Ahora vamos a analizar el cumplimiento de los supuestos del modelo lineal
```{r}
plot(modelo_log)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad se respeta. Podemos observar un comportamiento heterocedástico aunque parece ser más uniforme que el del *modelo_sup_descubierta*. Se resaltan 3 observaciones (observaciones 3636,3709,7346).
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho. Sin embargo parece que se comportan ligeramente mejor que el *modelo_sup_descubierta* (parecen estár mas suavizados los extremos).
- *Residual vs leverage:*. se pueden apreciar 2 puntos con un leverage bastante alto y el grafico resalta 3 observaciones.

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal.Sin embargo y de observar los gráficos, parece que se comporta mejor que el *modelo_sup_descubierta*.

## Selección del Modelo

Vamos a generar un nuevo modelo utilizando como variables $log(rooms)$, $log(bathrooms)$, $log(surface_total)$, **property_type** y **barrios** y otro similar a nuestro *modelo_log* reemplazando la variable **barrios** por la variable **l3**.

### Generación Nuevos Modelos

Generamos nuestro modelo *modelo_log_surface_total* que buscará inferir el resultado del $log(price)$
```{r}
modelo_log_surface_total = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_total) + property_type + barrios,
  data = train_ds
)
tidy_mlst <- tidy(modelo_log_surface_total, conf.int = TRUE)
tidy_mlst
```
En nuestro modelo podemos observar como el coeficiente de $log(rooms)$ parece no ser significativo (su p-valor = 0.5) y su intervalo de confianza incluye el 0. El resto de nuestros coeficientes parecen ser significativos.

Debido a que neustros coeficientes para la variable $log(rooms)$ parece que no son significativos, vamos a analizar si la interacción de la variable si lo es para nuestro modelo.
```{r}
tidy(
  anova(modelo_log_surface_total)
)
```
Y resulta que si lo es.

Analizamos el cumplimiento de los supuestos de nuestro modelo.
```{r}
plot(modelo_log_surface_total)
```
Podemos ver como nuestro modelo se comporta de forma muy similar al *modelo_log*. 
Sin embargo hay una diferencia importante al analizar **Residuos vs Leverage**. Aca podemos observar como hay una especie de corte en el leverage entre los valores de 0.0007 y 0.0013 (aproximadamente).

Generamos nuestro modelo *modelo_log_surface_total* que buscará inferir el resultado del $log(price)$
```{r}
modelo_log_l3 = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + sup_descubierta + l3 ,
  data = train_ds
)
tidy_mll3 <- tidy(modelo_log_l3, conf.int = TRUE)
tidy_mll3
```
En este modelo, podemos observar el mismo problema que surgía al incorporar al analisis la variable **l3**. Sin embargo, el resto de nuestros coeficientes parecen ser estadisticamente significativos.

Debido a que neustros coeficientes para la variable **l3** parece que no son significativos, vamos a analizar si la interacción de la variable si lo es para nuestro modelo.
```{r}
tidy(
  anova(modelo_log_l3)
)
```
Y resulta que si lo es.

Analizamos el cumplimiento de los supuestos de nuestro modelo.
```{r}
plot(modelo_log_l3)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad se respeta. Podemos observar un comportamiento heterocedástico (muy similar al *modelo_log*). Se resaltan 3 observaciones (observaciones 7346,7942, 28022).
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho. Sin embargo parece haber cierto suavizado en el extremo superior derecho en comparación a otros modelos.
- *Residual vs leverage:*. se pueden apreciar 3 puntos con un leverage bastante alto y el grafico resalta 3 observaciones (3636, 22246,26579).

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal. Parece que se comporta muy similar al *modelo_log* con una excepción al analizar el grafico de **Residual vs leverage**.

### Evaluación de Modelos Seleccionados

Ahora vamos a elegir 2 de los modelos previamente desarrollados para evaluar y seleccionar, junto a nuestros 2 nuevos modelos, cual es el que mejor permite inferir el precio de una propiedad.
Vamos a elegir los modelos que mejor expresan la variabilidad $Rˆ2$. Estos son el *modelo_log* y *modelo_sup_descubierta*.
```{r}
modelos = list(
  modelo_log = modelo_log,
  modelo_sup_descubierta = modelo_sup_descubierta,
  modelo_log_surface_total = modelo_log_surface_total,
  modelo_log_l3 = modelo_log_l3
)

purrr::map_df(modelos, broom::glance, .id = "model") %>%
  arrange(adj.r.squared)
```
Podemos observar que el modelo que mejor explica la variabilidad es el modelo *modelo_log_surface_total*. Observamos el valor del $Rˆ2$ ajustado.

### Predicción

Cargamos el dataset de testing y le aplicamos nuestras transformaciones.
```{r}
propiedades_test <- read_csv(here("/ds/ar_properties_test.csv"))

propiedades_test = propiedades_test %>%
  mutate(
    precio_m2 = price / surface_total,
    barrios = factor(
      case_when(
        precio_m2 <= quantile(precio_m2)[2] ~ "precio_bajo",
        precio_m2 > quantile(precio_m2)[2] & precio_m2 <= quantile(precio_m2)[4] ~ "precio_medio",
        precio_m2 > quantile(precio_m2)[4] ~ "precio_alto"
      )
    ),
    sup_descubierta = surface_total - surface_covered
  )

propiedades_test
```

#### Evaluamos en Training

Ahora vamos a evaluar nuestros modelos en training y evaluar sus predicciones en testing. Para esto es necesario hacer un análisis distinto para los modelos que utilizan $log$ que para el *modelo_sup_descubierta*.
```{r}
modelos_log = list(
  modelo_log = modelo_log,
  modelo_log_l3 = modelo_log_l3,
  modelo_log_surface_total = modelo_log_surface_total
)
```

```{r}
predicciones_training_log = map(.x = modelos_log, .f = augment)
```

```{r}
map_dfr(
  .x = predicciones_training_log, 
  .f = rmse, 
  truth = exp(`log(price)`), 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% arrange(.estimate)
```

```{r}
eval_train_sd = augment(modelo_sup_descubierta)
```

```{r}
rmse(
  data = eval_train_sd,
  truth = price,
  estimate = .fitted
)
```
Analizando los **RMSE** de nuestros modelos en training, podemos observar que el modelo con el menor valor es nuestro *modelo_sup_descubierta* seguido (en orden) por los modelos *modelo_log_surface_total*, *modelo_log*, *modelo_log_l3*.

#### Evaluamos en Testing

Ahora vamos a evaluar nuestros modelos en testing.
```{r}
# Aplicamos la función augment a los 4 modelos con el set de testing
predicciones_testing = map(
  .x = modelos_log, 
  .f = augment,
  newdata = propiedades_test
) 

# Obtenemos el RMSE para los 4 modelos
map_dfr(
  .x = predicciones_testing, 
  .f = rmse, 
  truth = price, 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% 
  arrange(.estimate)
```

```{r}
pred_log = augment(
  modelo_sup_descubierta, 
  newdata=propiedades_test
) 
pred_log
```

```{r}
rmse(
  data = pred_log, 
  truth = price, 
  estimate = .fitted
)
```
Volvemos a observar como el modelo con el menor valor de **RMSE** es nuestro *modelo_sup_descubierta*.

### Conclusion

En lineas generales no podemos afirmar que nuestros modelos cumplen los supuestos del modelo lineal.

Sin embargo, podemos utilizar nuestros modelos para predecir los valores del **precio** de las propiedades. Ahora bien, para elegir el mejor de los modelos propuestos, vamos a fundamentar nuestra decisión en base a la evaluación de las 2 métricas que estamos observando:
- $Rˆ2$
- **RMSE**

Los modelos que mejor explican la variabilidad medida por $Rˆ2$ ajustado son el *modelo_log*, *modelo_sup_descubierta* y *modelo_log_surface_total*. Todos estos modelos se encuentran con valores superiores a 0.91.

Sin embargo, nosotros queremos predecir nuevos datos y para ello es importante medir el **RMSE** para evaluar el error en la predicción. Al analizar esta metrica, observamos un salto importante entre nuestro *modelo_sup_descubierta* (38974.87) y sus seguidores *modelo_log_surface_total* (43832.07) y *modelo_log* (46152.97).

Por ende seleccionaría como mi mejor modelo el modelo **modelo_sup_descubierta**.



