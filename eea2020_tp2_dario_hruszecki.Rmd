---
title: "eea2020_tp2_dario_hruszecki"
author: "Darío Hruszecki"
output:
  html_document:
    toc: yes
    toc_depth: '6'
    df_print: paged
  html_notebook:
    theme: spacelab
    toc_depth: 6
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r}
# Carga de librerías
library(tidyverse)
library(tidymodels)
library(epiDisplay)
library(GGally)
library(corrr)
library(knitr)
library(ggrepel)
library(kableExtra)
library(here)
```

# EEA 2020 - TP2 - Darío Hruszecki

## DATOS

El dataset de precios de inmuebles proviene  de [Properati](https://www.properati.com.ar/data/). El mismo ya fue filtrado por los docentes y a su vez se encuentra particionado en subconjuntos de training y test.

### Carga partición de entrenamiento
```{r}
train_ds <- read_csv(here("/ds/ar_properties_train.csv"))
```

### Describimos el dataset

#### Previsualizamos los datos
```{r}
head(train_ds)
```
#### Vemos las dimensiones del dataset
```{r}
dim_desc(train_ds)
```

#### Vemos como se distribuyen los valores de las variables
```{r}
summary(train_ds)
```
#### Valores únicos para la variable alfanumérica *l3*
```{r}
unique(train_ds$l3)
```
#### Valores únicos para la variable alfanumérica *property_type*
```{r}
unique(train_ds$property_type)
```
#### Verificamos si hay valores NA en las variables
```{r}
apply(train_ds, 2, function(x) any(is.na(x)))
```
#### Calculamos la distribución de frecuencias para los valores de *property_type*
```{r}
tab1(train_ds$property_type, sort.group = "decreasing", cum.percent = TRUE)
```
#### Calculamos la distribución de frecuencias para los valores de *l3*
```{r}
tab1(train_ds$l3, sort.group = "decreasing", cum.percent = TRUE)
```
#### Observaciones sobre los datos
* El dataset contiene 8 variables y 32132 registros
* De las 8 variables, 5 son núnericas y 3 son alfanuméricas
* De las variables alfanuméricas tenemos el barrio (*l3*) y el tipo de propiedad (*property_type*). La tercera es un UUID para la propiedad (*id*)
* En base a los valores únicos encontrados para *l3* podemos inferir que las propiedades pertenecen a CABA en su totalidad.
* De las númericas, además del precio (*price*) tenemos variables que describen la propiedad: cantidad de habitaciones (*rooms*), cantidad de baños (*bathrooms*), supervicie total (*surface_total*) y superficie cubierta (*surface_covered*)
* No se observan valores NA en ninguna de las columnas
* Aproximadamente un 88% de las propiedades son de tipo Departamento
* Aproximadamente un 60% de las propiedades se encuentran en los neighborhood de Palermo, Belgrano, Almagro, Caballito, Villa Crespo, Recoleta, Barrio Norte y Villa Urquiza

## Modelo de Regresion Lineal Multiple

### Generación del Modelo con todas las covariables (lm_all)

```{r}
lm_all <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type + l3, data = train_ds)

tidy_lm_all <- tidy(lm_all, conf.int = TRUE)
tidy_lm_all
```

### Análisis del Modelo con todas las covariables

#### Significado de los coeficientes estimados

* **(intercept)** (-109143.7839): es una inferencia teórica del modelo, no representa la realidad, sería una propiedad sin superficie, habitaciones, barrio, etc.

* **rooms** (-4359.7289): Al ser negativo implica una quita promedio de ese valor en el precio de la propiedad al aumentar en 1 la cantidad de ambientes.

* **bathrooms** (34367.2123): Indica en cuanto aumenta en promedio el valor de la propiedad por agregar un baño.

* **surface_total** (890.5585): Indica en cuanto aumenta en promedio el valor de la propiedad por aumentas en 1 m2 la superficie total.

* **surface_covered** (1497.9310): Indica en cuanto aumenta en promedio el valor de la propiedad por aumentas en 1 m2 la superficie cubierta.

* **property_typeDepartamento** (91485.9410): El valor de β (91485.9410) indica cuanto aumenta la función de respuesta para un departamento en comparación de una casa.

* **property_typePH** (46220.0449): El valor de β (46220.0449) indica cuanto aumenta la función de respuesta para un PH en comparación de una casa.

* **l3{Barrio}** : Son 56 coeficientes que indican en cuanto aumenta o se disminuye en promedio el precio de una propiedad dependiendo del barrio en donde esta ubicada.

*Observación: para cada coeficiente se asume que se mantienen constantes el restos de las covariables*.

#### ¿Qué observamos al respecto de la significatividad de las variables dummy?

Analizando los p-valores de las variables dummies asociadas a **property_type** estas resultan estadísticamente significativas. Por otro lado, las variables dummies asociados a la variable **l3**  se reparten entre algunas significativas y otras no.

##### Aplicamos Test F 
```{r}
tidy(anova(lm_all))
```
Analizando la significatividad global de las variables **l3** y **property_type** y observando que tienen un p-valor menor a 0.5 se puede concluir que ambas son signigicativas.
 
#### Evaluación del Modelo

##### Resúmen global (glance) del modelo lm_all
```{r}
glance(lm_all)
```

#### Gráfico de coeficientes del modelo lm_all
```{r warning=FALSE, fig.width=15, fig.height=15}
ggplot(tidy_lm_all, 
  aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 1)) +
  geom_point(color = "blue", size=3) +
  geom_vline(xintercept = 0, lty = 2, color = "black") + 
  geom_errorbarh(color = "red", size=1) + 
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```

El **r.squared** en el resúmen global representa el $Rˆ2$ o coeficiente de determinación que refleja la bondad del ajuste del modelo a la variable precio. Al ser un valor cercano a 1 nos está diciendo que el modelo **lm_all** ajusta muy bien dicha variable.

Por otro lado, el gráfico nos permite visualizar con mayor claridad los intervalos de confiaza de de los coeficientes  de las variables dummies de **l3**. Muchas de ellas incluyen el cero, ergo estas variables podrían considerarse no significativas.

### Generación de un modelo lineal sin la covariable **l3**

```{r}
lm_wo_l3 <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type, data = train_ds)

tidy_lm_wo_l3 <- tidy(lm_wo_l3, conf.int = TRUE)
tidy_lm_wo_l3
```

##### Aplicamos Test F 
```{r}
tidy(
  anova(lm_wo_l3)
)
``` 

Al quitar la variable *l3* la cantidad de coeficientes se reduce considerablemente, no necesitamos graficar para indentificar que ningúno de los intervalos de confianza incluye el 0. 
Por otro lado todos los p-values son menores a 0.5 ergo las variables se pueden considerar significativas, esto tambien se ve confirmado por el resultado del Test F.

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all o lm_wo_l3)
```{r}
models = list(lm_all = lm_all, lm_wo_l3 = lm_wo_l3)

purrr::map_df(models, broom::glance, .id = "model")
```

El $Rˆ2$ de **lm_all**  es superior al del modelo **lm_wo_l3** por lo tanto el modelo que contiene todas las covariables es el que mejor explica la variable la variabilidad del precio.

## Creación de Variables

### Creación variable **neighborhood**

En el análisis anterior se observó que **l3** no es un buen agrupador, algunas de sus dummies eran significativas pero muchas otras no. Vamos a proceder a crear una nueva variable **neighborhood** que agrupe a las propiedad teniendo en cuenta el precio del metro cuadrado.

Es necesario tambien agregar otra variable auxiliar que contenta el precio por metro para luego poder hacer el agrupamiento necesario:

* *price_m_sq* =  *price_m_sq*  / *surface_total* 

La valores posibles de **neighborhood** van a ser: 

* *low_price* => *price_m_sq*  <= Q1 (*price_m_sq*)
* *medium_price* => *price_m_sq*  > Q1 (*price_m_sq*) &  *price_m_sq*  <= Q2 (*price_m_sq*)
* *high_price* => *price_m_sq*  > Q3 (*price_m_sq*)

```{r}
train_ds = train_ds %>% mutate(
    price_m_sq = price / surface_total,
    neighborhood = factor(
      case_when(
        price_m_sq <= quantile(price_m_sq)[2] ~ "low_price",
        price_m_sq > quantile(price_m_sq)[2] & price_m_sq <= quantile(price_m_sq)[4] ~ "medium_price",
        price_m_sq > quantile(price_m_sq)[4] ~ "high_price"
      )
    )
  )

train_ds
```

### Generamos modelo reemplazando *l3* por *neighborhood*

```{r}
lm_neighborhoods <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type + neighborhood, data = train_ds)

tify_lm_neighborhoods <- tidy(lm_neighborhoods, conf.int = TRUE)
tify_lm_neighborhoods
```

Observaciones:

* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas
* El intervalo de confianza del B0 contiene al cero

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all, lm_wo_l3 o lm_neighborhood)

```{r}
models = list( lm_all = lm_all, lm_wo_l3 = lm_wo_l3, lm_neighborhoods = lm_neighborhoods )

purrr::map_df(models, broom::glance, .id = "model") %>% arrange(adj.r.squared)
```

El modelo *lm_neighborhoods* supera al *lm_all* en el $Rˆ2$ y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades.

### Creación variable **surface_uncovered**

Las variables  **surface_total** y **surface_covered** están muy correlacionadas por lo que vamos a generar una nueva variable llamada **surface_uncovered** que representa la diferencia entre la superficie total y la cubierta.
```{r}
train_ds = train_ds %>% mutate(surface_uncovered = surface_total - surface_covered)

train_ds 
```

### Generamos modelo reemplazando *surface_total* por *surface_uncovered*

```{r}
lm_surface_uncovered <- lm( price ~ rooms + bathrooms + surface_uncovered + surface_covered + property_type + price_m_sq + neighborhood,  data = train_ds)

tidy_lm_surface_uncovered <- tidy(lm_surface_uncovered, conf.int = TRUE)
tidy_lm_surface_uncovered
```

Observaciones:

* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all, lm_wo_l3, lm_neighborhood o lm_surface_uncovered)

```{r}
models = list( lm_all = lm_all, lm_wo_l3 = lm_wo_l3, lm_neighborhoods = lm_neighborhoods, lm_surface_uncovered = lm_surface_uncovered )

purrr::map_df(models, broom::glance, .id = "model") %>% arrange(adj.r.squared)
```
El modelo *lm_surface_uncovered* supera al *lm_neighborhoods* en el $Rˆ2$ y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades.

## Diagnóstico del Modelo

```{r}
plot(lm_surface_uncovered)
```

Del plot de **Residual vs Fitted** se puede observar q no se respeta la linealidad parece que no se respeta y  por otro lado mientras aumentan las predicciones aumenta la heterocedasticidad, además existen varios puntos con un leverage alto que se pueden observar en el plot **Residual vs leverage**, donde al menos dos pueden ser outliers.
Por último en el plot **Normal Q-Q* se observa que los extremos no se ajustan a la distribución teórica.

En conclusión, el modelo *lm_surface_uncovered* no comple con los supuestos del modelo lineal.

## Modelo Log(price)

$$
log(price) = \beta_0 + \beta_1log(rooms) + \beta_2log(bathrooms) + \beta_3log(surface\_covered) + \beta_4property\_type + \beta_5neighborhood + \beta_6surface\_uncovered
$$

```{r}
lm_log = lm( log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + neighborhood + surface_uncovered, data = train_ds )

tidy_ml_log <- tidy(lm_log, conf.int = TRUE)
tidy_ml_log
```

### Aplicamos Test F 
```{r}
tidy(anova(lm_log))
```

Observaciones:

* De nuestro modelo confirmamos que todos los coeficientes resultan significativos.

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_surface_uncovered, lm_log)
```{r}
models = list( lm_log = lm_log, lm_surface_uncovered = lm_surface_uncovered )

purrr::map_df(models, broom::glance, .id = "model")
```
El modelo *lm_surface_uncovered* supera al *lm_logs* en el $Rˆ2$ y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades.

### Diagnóstico del modelo
```{r}
plot(lm_log)
```

Del plot de **Residual vs Fitted** se puede observar que se repeta cierta linealidad y,  por otro lado,  mientras aumentan las predicciones aumenta la heterocedasticidad, además se remarcan algunos puntos en el plot: 3636, 7346, 3709.  En **Residual vs leverage** vemos varios puntos con un leverage alto y se remarcan algunos puntos tambien.
Por último em **Normal Q-Q** se observa que los extremos no se ajustan a la distribución teórica.

En conclusión, el modelo *lm_log* no comple con los supuestos del modelo lineal.

## Selección del Modelo

Vamos a crear dos nuevos modelos

### Generación modelo Log(pricer) V2

$$
log(price) = \beta_0 + \beta_1log(surface\_total) + \beta_2log(bathrooms) + \beta_3log(surface\_covered) +  \beta_4property\_type + \beta_5neighborhood + \beta_6surface\_uncovered
$$

```{r}
lm_log_v2 = lm( log(price) ~ log(surface_total) + log(bathrooms) + log(surface_covered) + property_type + neighborhood + surface_uncovered, data = train_ds )

tidy_lm_log_v2 <- tidy(lm_log_v2, conf.int = TRUE)
tidy_lm_log_v2
```

Observaciones:

* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas

### Diagnóstico del modelo
```{r}
plot(lm_log_v2)
```

Podemos ver como el modelo se comporta de forma muy similar al *lm_log*. 

### Generación modelo Log(pricer) V3

$$
log(price) = \beta_0 + \beta_1log(surface\_total) + \beta_2log(bathrooms) + \beta_3log(surface\_covered) +  \beta_4neighborhood + \beta_5surface\_uncovered
$$


```{r}
lm_log_v3 = lm( log(price) ~ log(surface_total) + log(bathrooms) + log(surface_covered) + neighborhood + surface_uncovered, data = train_ds )

tidy_lm_log_v3 <- tidy(lm_log_v3, conf.int = TRUE)
tidy_lm_log_v3
```
Observaciones:

* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas

### Diagnóstico del modelo
```{r}
plot(lm_log_v3)
```

Podemos ver como el modelo se comporta de forma muy similar al *lm_log*. 

### Selección de modelos

Se seleccionan para evaluación los modelos logaritmicos **ml_log**, **ml_log_v2** y **ml_log_v3** y el modelo **lm_surface_uncovered**.

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_surface_uncovered, lm_log, lm_log_v2, lm_log_v3 )

```{r}
models = list(lm_surface_uncovered = lm_surface_uncovered, lm_log = lm_log, lm_log_v2 = lm_log_v2, lm_log_v3 = lm_log_v3 )

purrr::map_df(models, broom::glance, .id = "model") %>% arrange(adj.r.squared)
```

El modelo *lm_log_v2* supera al resto de los modelos en el $Rˆ2$ y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades. De todas formas hay que destacar que todos los modelos tienen un $Rˆ2$ mayor a 0.91.

### Predicción

#### Carga del dataset de testing
```{r}
test_ds <- read_csv(here("/ds/ar_properties_test.csv"))

test_ds = test_ds %>%
  mutate(
    price_m_sq = price / surface_total,
    neighborhood = factor(
      case_when(
        price_m_sq <= quantile(price_m_sq)[2] ~ "low_price",
        price_m_sq > quantile(price_m_sq)[2] & price_m_sq <= quantile(price_m_sq)[4] ~ "medium_price",
        price_m_sq > quantile(price_m_sq)[4] ~ "high_price"
      )
    ),
    surface_uncovered = surface_total - surface_covered
  )

test_ds
```

#### Evaluación en Training

##### Evaluación de modelos logaritmicos (**lm_log**, **lm_log_v2**, **lm_log_v3**)
```{r}
models_log = list(lm_log = lm_log, lm_log_v2 = lm_log_v2, lm_log_v3 = lm_log_v3 )
```

```{r}
pred_train_log = map(.x = models_log, .f = augment)
```

```{r}
map_dfr(
  .x = pred_train_log, 
  .f = rmse, 
  truth = exp(`log(price)`), 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% arrange(.estimate)
```
##### Evaluación del modelo no logaritmico (**lm_surface_uncovered**)

```{r}
pred_train_surface_uncovered = augment(lm_surface_uncovered)
```

```{r}
rmse(
  data = pred_train_surface_uncovered,
  truth = price,
  estimate = .fitted
)
```

De de los 4 modelos evaluados en training se destaca *lm_surface_uncovered* por tener el menor valor de **RMSE**.

#### Evaluación en Testing

##### Evaluación de modelos logaritmicos (**lm_log**, **lm_log_v2**, **lm_log_v3**)
```{r}
pred_test_log = map(
  .x = models_log, 
  .f = augment,
  newdata = test_ds
) 

map_dfr(
  .x = pred_test_log, 
  .f = rmse, 
  truth = price, 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% 
  arrange(.estimate)
```
##### Evaluación del modelo no logaritmico (**lm_surface_uncovered**)

```{r}
pred_test_surface_uncovered = augment(
  lm_surface_uncovered, 
  newdata=test_ds
) 
pred_test_surface_uncovered
```

```{r}
rmse(
  data = pred_test_surface_uncovered, 
  truth = price, 
  estimate = .fitted
)
```
De de los 4 modelos evaluados en testing se destaca *lm_surface_uncovered* por tener el menor valor de **RMSE** al igual que con el dataset de training.

### Conclusiones finales

De los 4 modelos evaluados el que se destaca por sobre el resto es **lm_surface_uncovered** que tiene un $Rˆ2$ alto de 0.9211874 que asegura una alta explicabilidad  del precio de las propiedades y además tiene el RMSE (error cuadrático medio) mas bajo lo cuál nos asegura que sus predicciones van a ser las mas cercanas a los valores reales.
Es para destacar que los 4 modelos seleccionados tienen un $Rˆ2$  mayor a 0.91 y que ninguno parecen cumplir los supuestos del modelo lineal. 





