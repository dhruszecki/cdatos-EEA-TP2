---
title: "eea2020_tp2_dario_hruszecki"
author: "Darío Hruszecki"
output:
  html_document:
    toc: yes
    toc_depth: '6'
    df_print: paged
  html_notebook:
    theme: spacelab
    toc_depth: 6
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r}
# Carga de librerías
library(tidyverse)
library(tidymodels)
library(epiDisplay)
library(GGally)
library(corrr)
library(knitr)
library(ggrepel)
library(kableExtra)
library(here)
```

# EEA 2020 - TP2 - Darío Hruszecki

## DATOS

El dataset de precios de inmuebles proviene  de [Properati](https://www.properati.com.ar/data/). El mismo ya fue filtrado por los docentes y a su vez se encuentra particionado en subconjuntos de training y test.

### Carga partición de entrenamiento
```{r}
train_ds <- read_csv(here("/ds/ar_properties_train.csv"))
```

### Describimos el dataset

#### Previsualizamos los datos
```{r}
head(train_ds)
```
#### Vemos las dimensiones del dataset
```{r}
dim_desc(train_ds)
```

#### Vemos como se distribuyen los valores de las variables
```{r}
summary(train_ds)
```
#### Valores únicos para la variable alfanumérica *l3*
```{r}
unique(train_ds$l3)
```
#### Valores únicos para la variable alfanumérica *property_type*
```{r}
unique(train_ds$property_type)
```
#### Verificamos si hay valores NA en las variables
```{r}
apply(train_ds, 2, function(x) any(is.na(x)))
```
#### Calculamos la distribución de frecuencias para los valores de *property_type*
```{r}
tab1(train_ds$property_type, sort.group = "decreasing", cum.percent = TRUE)
```
#### Calculamos la distribución de frecuencias para los valores de *l3*
```{r}
tab1(train_ds$l3, sort.group = "decreasing", cum.percent = TRUE)
```
#### Observaciones sobre los datos
* El dataset contiene 8 variables y 32132 registros
* De las 8 variables, 5 son núnericas y 3 son alfanuméricas
* De las variables alfanuméricas tenemos el barrio (*l3*) y el tipo de propiedad (*property_type*). La tercera es un UUID para la propiedad (*id*)
* En base a los valores únicos encontrados para *l3* podemos inferir que las propiedades pertenecen a CABA en su totalidad.
* De las númericas, además del precio (*price*) tenemos variables que describen la propiedad: cantidad de habitaciones (*rooms*), cantidad de baños (*bathrooms*), supervicie total (*surface_total*) y superficie cubierta (*surface_covered*)
* No se observan valores NA en ninguna de las columnas
* Aproximadamente un 88% de las propiedades son de tipo Departamento
* Aproximadamente un 60% de las propiedades se encuentran en los neighborhood de Palermo, Belgrano, Almagro, Caballito, Villa Crespo, Recoleta, Barrio Norte y Villa Urquiza

## Modelo de Regresion Lineal Multiple

### Generación del Modelo con todas las covariables (lm_all)

```{r}
lm_all <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type + l3, data = train_ds)

tidy_lm_all <- tidy(lm_all, conf.int = TRUE)
tidy_lm_all
```

### Análisis del Modelo con todas las covariables

#### Significado de los coeficientes estimados

* **(intercept)** (-109143.7839): es una inferencia teórica del modelo, no representa la realidad, sería una propiedad sin superficie, habitaciones, barrio, etc.

* **rooms** (-4359.7289): Al ser negativo implica una quita promedio de ese valor en el precio de la propiedad al aumentar en 1 la cantidad de ambientes.

* **bathrooms** (34367.2123): Indica en cuanto aumenta en promedio el valor de la propiedad por agregar un baño.

* **surface_total** (890.5585): Indica en cuanto aumenta en promedio el valor de la propiedad por aumentas en 1 m2 la superficie total.

* **surface_covered** (1497.9310): Indica en cuanto aumenta en promedio el valor de la propiedad por aumentas en 1 m2 la superficie cubierta.

* **property_typeDepartamento** (91485.9410): El valor de β (91485.9410) indica cuanto aumenta la función de respuesta para un departamento en comparación de una casa.

* **property_typePH** (46220.0449): El valor de β (46220.0449) indica cuanto aumenta la función de respuesta para un PH en comparación de una casa.

* **l3{Barrio}** : Son 56 coeficientes que indican en cuanto aumenta o se disminuye en promedio el precio de una propiedad dependiendo del barrio en donde esta ubicada.

*Observación: para cada coeficiente se asume que se mantienen constantes el restos de las covariables*.

#### ¿Qué observamos al respecto de la significatividad de las variables dummy?

Analizando los p-valores de las variables dummies asociadas a **property_type** estas resultan estadísticamente significativas. Por otro lado, las variables dummies asociados a la variable **l3**  se reparten entre algunas significativas y otras no.

##### Aplicamos Test F 
```{r}
tidy(anova(lm_all))
```
Analizando la significatividad global de las variables **l3** y **property_type** y observando que tienen un p-valor menor a 0.5 se puede concluir que ambas son signigicativas.
 
#### Evaluación del Modelo

##### Resúmen global (glance) del modelo lm_all
```{r}
glance(lm_all)
```

#### Gráfico de coeficientes del modelo lm_all
```{r warning=FALSE, fig.width=15, fig.height=15}
ggplot(tidy_lm_all, 
  aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 1)) +
  geom_point(color = "blue", size=3) +
  geom_vline(xintercept = 0, lty = 2, color = "black") + 
  geom_errorbarh(color = "red", size=1) + 
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```
El **r.squared** en el resúmen global representa el R cuadrado o coeficiente de determinación que refleja la bondad del ajuste del modelo a la variable precio. Al ser un valor cercano a 1 nos está diciendo que el modelo **lm_all** ajusta muy bien dicha variable.

Por otro lado, el gráfico nos permite visualizar con mayor claridad los intervalos de confiaza de de los coeficientes  de las variables dummies de **l3**. Muchas de ellas incluyen el cero, ergo estas variables podrían considerarse no significativas.

### Generación de un modelo lineal sin la covariable **l3**

```{r}
lm_wo_l3 <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type, data = train_ds)

tidy_lm_wo_l3 <- tidy(lm_wo_l3, conf.int = TRUE)
tidy_lm_wo_l3
```
##### Aplicamos Test F 
```{r}
tidy(
  anova(lm_wo_l3)
)
``` 
Al quitar la variable *l3* la cantidad de coeficientes se reduce considerablemente, no necesitamos graficar para indentificar que ningúno de los intervalos de confianza incluye el 0. 
Por otro lado todos los p-values son menores a 0.5 ergo las variables se pueden considerar significativas, esto tambien se ve confirmado por el resultado del Test F.

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all o lm_wo_l3)
```{r}
models = list(lm_all = lm_all, lm_wo_l3 = lm_wo_l3)

purrr::map_df(models, broom::glance, .id = "model")
```
El R cuadrado de **lm_all**  es superior al del modelo **lm_wo_l3** por lo tanto el modelo que contiene todas las covariables es el que mejor explica la variable la variabilidad del precio.

## Creación de Variables

### Creación variable **neighborhood**

En el análisis anterior se observó que **l3** no es un buen agrupador, algunas de sus dummies eran significativas pero muchas otras no. Vamos a proceder a crear una nueva variable **neighborhood** que agrupe a las propiedad teniendo en cuenta el precio del metro cuadrado.

Es necesario tambien agregar otra variable auxiliar que contenta el precio por metro para luego poder hacer el agrupamiento necesario:

* *price_m_sq* =  *price_m_sq*  / *surface_total* 

La valores posibles de **neighborhood** van a ser: 

* *low_price* => *price_m_sq*  <= Q1 (*price_m_sq*)
* *medium_price* => *price_m_sq*  > Q1 (*price_m_sq*) &  *price_m_sq*  <= Q2 (*price_m_sq*)
* *high_price* => *price_m_sq*  > Q3 (*price_m_sq*)

```{r}
train_ds = train_ds %>% mutate(
    price_m_sq = price / surface_total,
    neighborhood = factor(
      case_when(
        price_m_sq <= quantile(price_m_sq)[2] ~ "low_price",
        price_m_sq > quantile(price_m_sq)[2] & price_m_sq <= quantile(price_m_sq)[4] ~ "medium_price",
        price_m_sq > quantile(price_m_sq)[4] ~ "high_price"
      )
    )
  )

train_ds
```

### Generamos modelo reemplazando *l3* por *neighborhood*

```{r}
lm_neighborhoods <- lm(price ~ rooms + bathrooms + surface_total + surface_covered + property_type + neighborhood, data = train_ds)

tify_lm_neighborhoods <- tidy(lm_neighborhoods, conf.int = TRUE)
tify_lm_neighborhoods
```

Observaciones
* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas
* El intervalo de confianza del B0 contiene al cero

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all, lm_wo_l3 o lm_neighborhood)

```{r}
models = list( lm_all = lm_all, lm_wo_l3 = lm_wo_l3, lm_neighborhoods = lm_neighborhoods )

purrr::map_df(models, broom::glance, .id = "model") %>% arrange(adj.r.squared)
```
El modelo *lm_neighborhoods* supera al *lm_all* en el R cuadrado y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades.

### Creación variable **surface_uncovered**

Las variables  **surface_total** y **surface_covered** están muy correlacionadas por lo que vamos a generar una nueva variable llamada **surface_uncovered** que representa la diferencia entre la superficie total y la cubierta.
```{r}
train_ds = train_ds %>% mutate(surface_uncovered = surface_total - surface_covered)

train_ds 
```

### Generamos modelo reemplazando *surface_total* por *surface_uncovered*

```{r}
lm_surface_uncovered <- lm( price ~ rooms + bathrooms + surface_uncovered + surface_covered + property_type + price_m_sq + neighborhood,  data = train_ds)

tidy_lm_surface_uncovered <- tidy(lm_surface_uncovered, conf.int = TRUE)
tidy_lm_surface_uncovered
```
Observaciones
* Todas los coeficientes tiene p-value menor a 0.5 por lo tanto las variables son significativas

### Determinamos cuál modelo explica mejor la variabilidad del precio (lm_all, lm_wo_l3, lm_neighborhood o lm_surface_uncovered)

```{r}
models = list( lm_all = lm_all, lm_wo_l3 = lm_wo_l3, lm_neighborhoods = lm_neighborhoods, lm_surface_uncovered = lm_surface_uncovered )

purrr::map_df(models, broom::glance, .id = "model") %>% arrange(adj.r.squared)
```
El modelo *lm_surface_uncovered	* supera al *lm_neighborhoods* en el R cuadrado y por lo tanto tiene mayor explicabilidad sobre la variabilidad del precio de las propiedades.

## Diagnóstico del Modelo

Vamos a evaluar nuestro modelo lineal con la variable **sup_descubierta**
```{r}
plot(lm_surface_uncovered)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad parece que no se respeta. Vemos la existencía de heterocedasticidad a medida que aumentan las predicciones. Se resaltan 2 observaciones.
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho.
- *Residual vs leverage:*Existen cuatro puntos con un leverage bastante alto. Y se identifican 2 puntos como posibles outliers. .

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal. No parece ser concluyente respecto de la homocedasticidad, definitivamente existe una falta de normalidad y hay presencia de observaciones de alto leverage

## Modelo Log(*price*)

Vamos a generar un modelo para predecir el logaritmo natural de la variable **price**
$$
log(price) = \beta_0 + \beta_1log(rooms) + \beta_2log(bathrooms) + \beta_3log(surface\_covered) + \beta_4property\_type + \beta_5barrio + \beta_6surface\_patio
$$

Para esto vamos a generar nuestros nuevas variables
```{r}
modelo_log = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + neighborhood + sup_descubierta,
  data = train_ds
)
tidy_ml <- tidy(modelo_log, conf.int = TRUE)
tidy_ml
```

```{r}
tidy(
  anova(modelo_log)
)
```
De nuestro modelo confirmamos que todos los coeficientes resultan significativos.

Ahora comparamos nuestro nuevo *modelo_log* con nuestro *lm_surface_uncovered*.
```{r}
modelos = list(
  modelo_log = modelo_log,
  lm_surface_uncovered = lm_surface_uncovered
)

purrr::map_df(modelos, broom::glance, .id = "model")
```
Observamos que el mismo explica mejor la variabilidad $Rˆ2$

Ahora vamos a analizar el cumplimiento de los supuestos del modelo lineal
```{r}
plot(modelo_log)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad se respeta. Podemos observar un comportamiento heterocedástico aunque parece ser más uniforme que el del *lm_surface_uncovered*. Se resaltan 3 observaciones (observaciones 3636,3709,7346).
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho. Sin embargo parece que se comportan ligeramente mejor que el *lm_surface_uncovered* (parecen estár mas suavizados los extremos).
- *Residual vs leverage:*. se pueden apreciar 2 puntos con un leverage bastante alto y el grafico resalta 3 observaciones.

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal.Sin embargo y de observar los gráficos, parece que se comporta mejor que el *lm_surface_uncovered*.

## Selección del Modelo

Vamos a generar un nuevo modelo utilizando como variables $log(rooms)$, $log(bathrooms)$, $log(surface_total)$, **property_type** y **neighborhood** y otro similar a nuestro *modelo_log* reemplazando la variable **neighborhood** por la variable **l3**.

### Generación Nuevos Modelos

Generamos nuestro modelo *modelo_log_surface_total* que buscará inferir el resultado del $log(price)$
```{r}
modelo_log_surface_total = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_total) + property_type + neighborhood,
  data = train_ds
)
tidy_mlst <- tidy(modelo_log_surface_total, conf.int = TRUE)
tidy_mlst
```
En nuestro modelo podemos observar como el coeficiente de $log(rooms)$ parece no ser significativo (su p-valor = 0.5) y su intervalo de confianza incluye el 0. El resto de nuestros coeficientes parecen ser significativos.

Debido a que neustros coeficientes para la variable $log(rooms)$ parece que no son significativos, vamos a analizar si la interacción de la variable si lo es para nuestro modelo.
```{r}
tidy(
  anova(modelo_log_surface_total)
)
```
Y resulta que si lo es.

Analizamos el cumplimiento de los supuestos de nuestro modelo.
```{r}
plot(modelo_log_surface_total)
```
Podemos ver como nuestro modelo se comporta de forma muy similar al *modelo_log*. 
Sin embargo hay una diferencia importante al analizar **Residuos vs Leverage**. Aca podemos observar como hay una especie de corte en el leverage entre los valores de 0.0007 y 0.0013 (aproximadamente).

Generamos nuestro modelo *modelo_log_surface_total* que buscará inferir el resultado del $log(price)$
```{r}
modelo_log_l3 = lm(
  log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + sup_descubierta + l3 ,
  data = train_ds
)
tidy_mll3 <- tidy(modelo_log_l3, conf.int = TRUE)
tidy_mll3
```
En este modelo, podemos observar el mismo problema que surgía al incorporar al analisis la variable **l3**. Sin embargo, el resto de nuestros coeficientes parecen ser estadisticamente significativos.

Debido a que neustros coeficientes para la variable **l3** parece que no son significativos, vamos a analizar si la interacción de la variable si lo es para nuestro modelo.
```{r}
tidy(
  anova(modelo_log_l3)
)
```
Y resulta que si lo es.

Analizamos el cumplimiento de los supuestos de nuestro modelo.
```{r}
plot(modelo_log_l3)
```
- *Residuos vs valores predichos:* parece existir  una cierta estructura en los datos. La linealidad se respeta. Podemos observar un comportamiento heterocedástico (muy similar al *modelo_log*). Se resaltan 3 observaciones (observaciones 7346,7942, 28022).
- *Normal QQ plot:* los extremos no se ajustan a la distribución teórica, tanto inferior izquierdo como superior derecho. Sin embargo parece haber cierto suavizado en el extremo superior derecho en comparación a otros modelos.
- *Residual vs leverage:*. se pueden apreciar 3 puntos con un leverage bastante alto y el grafico resalta 3 observaciones (3636, 22246,26579).

- **Diagnóstico del modelo:** El modelo creado no cumple con los supuestos del modelo lineal. Parece que se comporta muy similar al *modelo_log* con una excepción al analizar el grafico de **Residual vs leverage**.

### Evaluación de Modelos Seleccionados

Ahora vamos a elegir 2 de los modelos previamente desarrollados para evaluar y seleccionar, junto a nuestros 2 nuevos modelos, cual es el que mejor permite inferir el precio de una propiedad.
Vamos a elegir los modelos que mejor expresan la variabilidad $Rˆ2$. Estos son el *modelo_log* y *lm_surface_uncovered*.
```{r}
modelos = list(
  modelo_log = modelo_log,
  lm_surface_uncovered = lm_surface_uncovered,
  modelo_log_surface_total = modelo_log_surface_total,
  modelo_log_l3 = modelo_log_l3
)

purrr::map_df(modelos, broom::glance, .id = "model") %>%
  arrange(adj.r.squared)
```
Podemos observar que el modelo que mejor explica la variabilidad es el modelo *modelo_log_surface_total*. Observamos el valor del $Rˆ2$ ajustado.

### Predicción

Cargamos el dataset de testing y le aplicamos nuestras transformaciones.
```{r}
propiedades_test <- read_csv(here("/ds/ar_properties_test.csv"))

propiedades_test = propiedades_test %>%
  mutate(
    price_m_sq = price / surface_total,
    neighborhood = factor(
      case_when(
        price_m_sq <= quantile(price_m_sq)[2] ~ "low_price",
        price_m_sq > quantile(price_m_sq)[2] & price_m_sq <= quantile(price_m_sq)[4] ~ "medium_price",
        price_m_sq > quantile(price_m_sq)[4] ~ "high_price"
      )
    ),
    sup_descubierta = surface_total - surface_covered
  )

propiedades_test
```

#### Evaluamos en Training

Ahora vamos a evaluar nuestros modelos en training y evaluar sus predicciones en testing. Para esto es necesario hacer un análisis distinto para los modelos que utilizan $log$ que para el *lm_surface_uncovered*.
```{r}
modelos_log = list(
  modelo_log = modelo_log,
  modelo_log_l3 = modelo_log_l3,
  modelo_log_surface_total = modelo_log_surface_total
)
```

```{r}
predicciones_training_log = map(.x = modelos_log, .f = augment)
```

```{r}
map_dfr(
  .x = predicciones_training_log, 
  .f = rmse, 
  truth = exp(`log(price)`), 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% arrange(.estimate)
```

```{r}
eval_train_sd = augment(lm_surface_uncovered)
```

```{r}
rmse(
  data = eval_train_sd,
  truth = price,
  estimate = .fitted
)
```
Analizando los **RMSE** de nuestros modelos en training, podemos observar que el modelo con el menor valor es nuestro *lm_surface_uncovered* seguido (en orden) por los modelos *modelo_log_surface_total*, *modelo_log*, *modelo_log_l3*.

#### Evaluamos en Testing

Ahora vamos a evaluar nuestros modelos en testing.
```{r}
# Aplicamos la función augment a los 4 modelos con el set de testing
predicciones_testing = map(
  .x = modelos_log, 
  .f = augment,
  newdata = propiedades_test
) 

# Obtenemos el RMSE para los 4 modelos
map_dfr(
  .x = predicciones_testing, 
  .f = rmse, 
  truth = price, 
  estimate = exp(.fitted), 
  .id="modelo"
) %>% 
  arrange(.estimate)
```

```{r}
pred_log = augment(
  lm_surface_uncovered, 
  newdata=propiedades_test
) 
pred_log
```

```{r}
rmse(
  data = pred_log, 
  truth = price, 
  estimate = .fitted
)
```
Volvemos a observar como el modelo con el menor valor de **RMSE** es nuestro *lm_surface_uncovered*.

### Conclusion

En lineas generales no podemos afirmar que nuestros modelos cumplen los supuestos del modelo lineal.

Sin embargo, podemos utilizar nuestros modelos para predecir los valores del **precio** de las propiedades. Ahora bien, para elegir el mejor de los modelos propuestos, vamos a fundamentar nuestra decisión en base a la evaluación de las 2 métricas que estamos observando:
- $Rˆ2$
- **RMSE**

Los modelos que mejor explican la variabilidad medida por $Rˆ2$ ajustado son el *modelo_log*, *lm_surface_uncovered* y *modelo_log_surface_total*. Todos estos modelos se encuentran con valores superiores a 0.91.

Sin embargo, nosotros queremos predecir nuevos datos y para ello es importante medir el **RMSE** para evaluar el error en la predicción. Al analizar esta metrica, observamos un salto importante entre nuestro *lm_surface_uncovered* (38974.87) y sus seguidores *modelo_log_surface_total* (43832.07) y *modelo_log* (46152.97).

Por ende seleccionaría como mi mejor modelo el modelo **lm_surface_uncovered**.



